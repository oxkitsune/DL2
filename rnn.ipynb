{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from transformer_rnn import TransformerRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvRNNCell(nn.Module):\n",
    "    def __init__(self, input_channels, hidden_channels, kernel_size):\n",
    "        super(ConvRNNCell, self).__init__()\n",
    "        self.hidden_channels = hidden_channels\n",
    "        padding = kernel_size // 2  # same padding\n",
    "        self.conv = nn.Conv2d(in_channels=input_channels + hidden_channels,\n",
    "                              out_channels=hidden_channels,\n",
    "                              kernel_size=kernel_size,\n",
    "                              padding=padding)\n",
    "\n",
    "    def forward(self, x, hidden_state):\n",
    "        combined = torch.cat([x, hidden_state], dim=1)  # concatenate along channel axis\n",
    "        hidden_state = torch.tanh(self.conv(combined))\n",
    "        return hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvRNN(nn.Module):\n",
    "    def __init__(self, input_channels, hidden_channels, kernel_size, num_layers):\n",
    "        super(ConvRNN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.cells = nn.ModuleList([\n",
    "            ConvRNNCell(input_channels if i == 0 else hidden_channels, hidden_channels, kernel_size)\n",
    "            for i in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, h_0=None):\n",
    "        batch_size, seq_len, channels, height, width = x.size()\n",
    "        \n",
    "        # Initialize hidden states if not provided\n",
    "        if h_0 is None:\n",
    "            h_0 = [torch.zeros(batch_size, self.hidden_channels, height, width).to(x.device)\n",
    "                   for _ in range(self.num_layers)]\n",
    "        \n",
    "        hidden_states = h_0\n",
    "        outputs = []\n",
    "\n",
    "        for t in range(seq_len):\n",
    "            input_t = x[:, t]\n",
    "            for i, cell in enumerate(self.cells):\n",
    "                hidden_states[i] = cell(input_t, hidden_states[i])\n",
    "                input_t = hidden_states[i]\n",
    "            outputs.append(hidden_states[-1])\n",
    "        \n",
    "        outputs = torch.stack(outputs, dim=1)\n",
    "        return outputs, hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "import transformer_rnn\n",
    "\n",
    "import importlib\n",
    "importlib.reload(transformer_rnn)\n",
    "\n",
    "depth, height, width = 128, 128, 128 # Generating random 3D data for CT, PTV, OAR, and a target dose\n",
    "\n",
    "# Generating random data\n",
    "ct = torch.rand(1, 1, depth, height, width, device=device)  # 1 batch, 1 channel, depth, height, width\n",
    "ptv = torch.rand(1, 1, depth, height, width, device=device)\n",
    "oar = torch.rand(1, 1, depth, height, width, device=device)\n",
    "target_dose = torch.rand(1, 1, depth, height, width, device=device)  # This is what the model will learn to predict\n",
    "\n",
    "unetr = transformer_rnn.TransformerRNN(input_dim=3, output_dim=1).to(device)\n",
    "combined_input = torch.cat((ct, ptv, oar), dim=1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape:  torch.Size([1, 128, 256, 12, 16])\n",
      "h0 shape:  torch.Size([1, 96, 12, 16])\n",
      "output shape:  torch.Size([1, 128, 96, 12, 16])\n",
      "output shape:  torch.Size([1, 3, 128, 128, 48])\n",
      "output shape:  torch.Size([1, 3, 128, 128, 128])\n",
      "torch.Size([1, 3, 128, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "output = unetr(combined_input)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:  torch.Size([1, 10, 3, 12, 16])\n",
      "Hidden state shape:  [torch.Size([1, 96, 12, 16])]\n",
      "Output shape:  torch.Size([1, 10, 96, 12, 16])\n",
      "Hidden state shape:  [torch.Size([1, 96, 12, 16])]\n"
     ]
    }
   ],
   "source": [
    "B = 1  # Batch size\n",
    "T = 10  # Sequence length (number of time steps)\n",
    "C_in = 3  # Number of input channels\n",
    "H = 12  # Height\n",
    "W = 16  # Width\n",
    "\n",
    "x = torch.randn(B, T, C_in, H, W)  # Example input tensor\n",
    "\n",
    "# Define ConvRNN parameters\n",
    "input_channels = C_in\n",
    "hidden_channels = 96\n",
    "kernel_size = 3\n",
    "num_layers = 1\n",
    "\n",
    "# Initialize the ConvRNN model\n",
    "model = ConvRNN(input_channels, hidden_channels, kernel_size, num_layers)\n",
    "\n",
    "# Initialize hidden state with the correct shape\n",
    "h_0 = [torch.zeros(B, hidden_channels, H, W)]\n",
    "\n",
    "print(\"Input shape: \", x.shape)\n",
    "print(\"Hidden state shape: \", [h.shape for h in h_0])\n",
    "\n",
    "# Forward pass\n",
    "outputs, hidden_states = model(x, h_0)\n",
    "print(\"Output shape: \", outputs.shape)\n",
    "print(\"Hidden state shape: \", [h.shape for h in hidden_states])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h shape: torch.Size([1, 1, 2304])\n",
      "Sequence length: 128\n",
      "x shape: torch.Size([1, 128, 3, 128, 128])\n",
      "torch.Size([1, 128, 5, 128, 128])\n",
      "torch.Size([1, 5, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "# feature_map, z3, z6, z9 = unetr(combined_input)\n",
    "\n",
    "# # concatentate z3, z6, z9\n",
    "# z = torch.cat((z3, z6, z9), dim=2) # shape: [1, 96, 12, 4, 4])\n",
    "\n",
    "# # flatten\n",
    "# h = z.view(1, 1, -1)\n",
    "# print(f\"h shape: {h.shape}\")\n",
    "\n",
    "# step_size_input = 1\n",
    "# seq_len = combined_input.shape[2] // step_size_input\n",
    "# print(f\"Sequence length: {seq_len}\")\n",
    "\n",
    "# x = [combined_input[:, :, i:i+step_size_input, ...] for i in range(0, combined_input.shape[2], step_size_input)]\n",
    "# x = torch.stack(x, dim=1) # we now have batch, seq_len, channel, 1, height, width\n",
    "# x = x.squeeze(3)\n",
    "# print(f\"x shape: {x.shape}\")\n",
    "# batch, seq_len, channel, height, width = x.shape\n",
    "# # # flatten the last 3 dims\n",
    "# # x = x.view(batch, seq_len, channel * step_size_input * height * width)\n",
    "\n",
    "# # print(f\"encoded states shape: {x.shape}\")\n",
    "# input_channels = channel\n",
    "# hidden_channels = 5\n",
    "# hidden_size = h.shape[2]\n",
    "# num_layers = 1\n",
    "# kernel_size = 3\n",
    "\n",
    "# conv_rnn = ConvRNN(input_channels, hidden_channels, kernel_size, num_layers).to(device)\n",
    "\n",
    "# # h with shape (batch_size, self.hidden_channels, height, width)\n",
    "\n",
    "# outputs, hidden_states = conv_rnn(x)\n",
    "# print(outputs.shape)\n",
    "# print(hidden_states[0].shape)\n",
    "\n",
    "\n",
    "\n",
    "# from torch.nn import RNN\n",
    "\n",
    "# rnn = RNN(input_size, hidden_size, num_layers, batch_first=True).to(device)\n",
    "\n",
    "# output, h_n = rnn(x, h)\n",
    "\n",
    "# print(f\"RNN output shape: {output.shape}\")\n",
    "# print(f\"RNN h_n shape: {h_n.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/thijm/GitHub/Master_related/DL2/.venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv3d(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h shape: torch.Size([1, 1, 2304])\n",
      "Sequence length: 16\n",
      "encoded states shape: torch.Size([1, 16, 393216])\n",
      "RNN output shape: torch.Size([1, 16, 2304])\n",
      "RNN h_n shape: torch.Size([1, 1, 2304])\n"
     ]
    }
   ],
   "source": [
    "feature_map, z3, z6, z9 = unetr(combined_input)\n",
    "\n",
    "# concatentate z3, z6, z9\n",
    "z = torch.cat((z3, z6, z9), dim=2) # shape: [1, 96, 12, 4, 4])\n",
    "\n",
    "# flatten\n",
    "h = z.view(1, 1, -1)\n",
    "print(f\"h shape: {h.shape}\")\n",
    "\n",
    "step_size_input = 8\n",
    "seq_len = combined_input.shape[2] // step_size_input\n",
    "print(f\"Sequence length: {seq_len}\")\n",
    "\n",
    "x = [combined_input[:, :, i:i+step_size_input, ...] for i in range(0, combined_input.shape[2], step_size_input)]\n",
    "x = torch.stack(x, dim=1) # we now have batch, seq_len, channel, step_size_input, height, width\n",
    "\n",
    "batch, seq_len, channel, step_size_input, height, width = x.shape\n",
    "\n",
    "# flatten the last 3 dims\n",
    "x = x.view(batch, seq_len, channel * step_size_input * height * width)\n",
    "print(f\"encoded states shape: {x.shape}\")\n",
    "\n",
    "\n",
    "input_size = x.shape[2]\n",
    "# hidden_size = z.shape[1]\n",
    "hidden_size = h.shape[2]\n",
    "num_layers = 1\n",
    "\n",
    "from torch.nn import RNN\n",
    "\n",
    "rnn = RNN(input_size, hidden_size, num_layers, batch_first=True).to(device)\n",
    "\n",
    "output, h_n = rnn(x, h)\n",
    "\n",
    "print(f\"RNN output shape: {output.shape}\")\n",
    "print(f\"RNN h_n shape: {h_n.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class RNN(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "#         super(RNN, self).__init__()\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.num_layers = num_layers\n",
    "#         self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "#         self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         # Set initial hidden and cell states \n",
    "#         h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "#         c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "#         # Forward propagate LSTM\n",
    "#         out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        \n",
    "#         # Decode the hidden state of the last time step\n",
    "#         out = self.fc(out[:, -1, :])\n",
    "#         return out\n",
    "    \n",
    "    \n",
    "# import torch rnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalMGRU(nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        #self.SourceAxisDistance = config.source_axis\n",
    "        #self.res_y = config.res_axis\n",
    "        #self.NH = config.n_hidden\n",
    "\n",
    "        self.SourceAxisDistance = 100.0\n",
    "        self.res_y = 0.25\n",
    "        self.NH = 64\n",
    "\n",
    "        n_kernel = 3\n",
    "        self.NY = 6\n",
    "        self.NX = 4\n",
    "\n",
    "        self.convXR = nn.Conv2d(self.NX, self.NH, n_kernel, padding='same', padding_mode='replicate')\n",
    "        self.convXZ = nn.Conv2d(self.NX, self.NH, n_kernel, padding='same', padding_mode='replicate')\n",
    "        self.convXN = nn.Conv2d(self.NX, self.NH, n_kernel, padding='same', padding_mode='replicate')\n",
    "\n",
    "        self.linYR = nn.Linear(self.NY, self.NH)\n",
    "        self.linYZ = nn.Linear(self.NY, self.NH)\n",
    "        self.linYN = nn.Linear(self.NY, self.NH)\n",
    "\n",
    "        self.convHR = nn.Conv2d(self.NH, self.NH, n_kernel, padding='same', padding_mode='replicate')\n",
    "        self.convHZ = nn.Conv2d(self.NH, self.NH, n_kernel, padding='same', padding_mode='replicate')\n",
    "        self.convHN = nn.Conv2d(self.NH, self.NH, n_kernel, padding='same', padding_mode='replicate')\n",
    "\n",
    "        self.linearOut = nn.Linear(self.NH, 8)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, gantry, Fluence, Grid, Slices_CT, ymin):\n",
    "        dimB = Grid.size(0)\n",
    "        dimX = Grid.size(2)\n",
    "        dimY = len(Slices_CT)\n",
    "        dimZ = Grid.size(1)\n",
    "        #device0 = Segment.device\n",
    "        #collimatorAngle = Segment[:, 0]\n",
    "        #gantryAngle = Segment[:, 2:4]\n",
    "        device0 = \"cuda:0\"\n",
    "        nb=2\n",
    "        #collimatorAngle = torch.full((nb,), 20.0, device=device0, dtype=torch.float64)\n",
    "        #gantryAngle = torch.full((nb,), gantry, device=device0, dtype=torch.float64)\n",
    "        collimatorAngle = torch.full((nb,), 20.0, device=device0)\n",
    "        gantryAngle = torch.full((nb,), gantry, device=device0)\n",
    "\n",
    "        #print(Grid.permute(0, 3, 1, 2).shape)   -> ([4, 2, 23, 23])\n",
    "        print(Fluence.unsqueeze(1).shape)\n",
    "\n",
    "        XI_ = torch.cat((Grid.permute(0, 3, 1, 2), Fluence.unsqueeze(1)), dim=1)\n",
    "        '''\n",
    "        YI_ = torch.stack(\n",
    "            (collimatorAngle.deg2rad().sin(), collimatorAngle.deg2rad().cos(),\n",
    "             (gantryAngle[:, 1] - gantryAngle[:, 0]).deg2rad().sin(),\n",
    "             (gantryAngle[:, 1] - gantryAngle[:, 0]).deg2rad().cos()\n",
    "             ), dim=-1)\n",
    "        '''\n",
    "\n",
    "        YI_ = torch.stack(\n",
    "            (collimatorAngle.deg2rad().sin(), collimatorAngle.deg2rad().cos(),\n",
    "             (gantryAngle).deg2rad().sin(),\n",
    "             (gantryAngle).deg2rad().cos()\n",
    "             ), dim=-1)\n",
    "\n",
    "        h0 = torch.zeros((1, 1, 1, 1), dtype=torch.float32, device=device0).expand(dimB, self.NH, dimZ, dimX)\n",
    "\n",
    "        out = []\n",
    "        for y in range(dimY):\n",
    "            ### conic effect\n",
    "            ycoor = (ymin + y) * self.res_y\n",
    "            xz_fac = (self.SourceAxisDistance + ycoor) / self.SourceAxisDistance\n",
    "            ### conic effect\n",
    "\n",
    "            XI = torch.cat((Slices_CT[y].unsqueeze(1), XI_), dim=1)\n",
    "            YI = torch.cat(\n",
    "                (YI_, torch.tensor((ycoor, xz_fac), dtype=torch.float32, device=device0).unsqueeze(0).expand(dimB, -1)),\n",
    "                dim=-1)\n",
    "\n",
    "            r = self.sigmoid(self.convXR(XI) + self.linYR(YI).unsqueeze(-1).unsqueeze(-1) + self.convHR(h0))\n",
    "            z = self.sigmoid(self.convXZ(XI) + self.linYZ(YI).unsqueeze(-1).unsqueeze(-1) + self.convHZ(h0))\n",
    "            n = torch.tanh(self.convXN(XI) + self.linYN(YI).unsqueeze(-1).unsqueeze(-1) + r * self.convHN(h0))\n",
    "\n",
    "            ht = (1 - z) * n + z * h0\n",
    "\n",
    "            out.append(ht)\n",
    "\n",
    "            h0 = ht\n",
    "\n",
    "        return self.linearOut(torch.stack(out, dim=3).permute(0, 2, 3, 4, 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
